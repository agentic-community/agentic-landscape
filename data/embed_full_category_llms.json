{"github_data":{"https://github.com/sgl-project/sglang":{"contributors":{"count":1101,"url":"https://github.com/sgl-project/sglang/graphs/contributors"},"description":"SGLang is a high-performance serving framework for large language models and multimodal models.","generated_at":"2026-02-16T20:38:18.389722066Z","latest_commit":{"ts":"2026-02-16T19:50:39Z","url":"https://github.com/sgl-project/sglang/commit/1b659bcb088fd303ee472c0720eeb1a3797cffa1"},"participation_stats":[58,64,126,127,79,120,55,110,106,130,96,85,90,85,114,79,109,89,93,85,65,98,102,159,159,164,139,135,133,173,140,139,125,167,192,213,185,192,268,213,190,236,303,240,199,222,297,177,211,192,143,191],"stars":23549,"topics":["attention","blackwell","cuda","deepseek","diffusion","glm","gpt-oss","inference","llama","llm","minimax","moe","qwen","qwen-image","reinforcement-learning","transformer","vlm","wan"],"url":"https://github.com/sgl-project/sglang","first_commit":{"ts":"2023-10-09T22:41:15Z","url":"https://github.com/sgl-project/sglang/commit/f6d40df0ee1e1fc53db3edc04bf90575f221cf23"},"languages":{"C":128264,"C++":1382831,"CMake":31951,"Cuda":1683302,"Dockerfile":80707,"Go":105506,"HIP":15490,"Jinja":1205,"Jupyter Notebook":7306,"Makefile":23168,"Python":25582937,"Rust":3035844,"Shell":158702,"Vim Script":914},"latest_release":{"ts":"2026-01-23T22:09:28Z","url":"https://github.com/sgl-project/sglang/releases/tag/v0.5.8"},"license":"Apache License 2.0"},"https://github.com/vllm-project/vllm":{"contributors":{"count":2202,"url":"https://github.com/vllm-project/vllm/graphs/contributors"},"description":"A high-throughput and memory-efficient inference and serving engine for LLMs","generated_at":"2026-02-16T20:38:26.414111819Z","latest_commit":{"ts":"2026-02-16T18:15:32Z","url":"https://github.com/vllm-project/vllm/commit/3b30e6150777de549b11f67dde3ecc0d3b1f3f50"},"participation_stats":[129,122,163,151,150,166,147,154,107,179,172,134,164,163,150,129,124,114,112,138,172,162,195,226,193,204,191,211,146,253,268,250,189,201,237,153,172,182,250,237,210,225,219,191,118,72,265,181,197,229,230,214],"stars":70418,"topics":["amd","blackwell","cuda","deepseek","deepseek-v3","gpt","gpt-oss","inference","kimi","llama","llm","llm-serving","model-serving","moe","openai","pytorch","qwen","qwen3","tpu","transformer"],"url":"https://github.com/vllm-project/vllm","first_commit":{"ts":"2023-02-09T11:24:15Z","url":"https://github.com/vllm-project/vllm/commit/e7d9d9c08c79b386f6d0477e87b77a572390317d"},"languages":{"C":95214,"C++":1260879,"CMake":98450,"Cuda":2024623,"Dockerfile":35685,"HCL":1731,"Jinja":6380,"Python":26372976,"Shell":258453},"latest_release":{"ts":"2026-02-04T20:48:08Z","url":"https://github.com/vllm-project/vllm/releases/tag/v0.15.1"},"license":"Apache License 2.0"}},"items":[{"category":"LLMs","homepage_url":"https://vllm.ai/","id":"llms--serving--vllm","logo":"logos/789d223c86d7884c48ea51f8e799e8c0ce952495186131fcaed24c06292d0e45.svg","name":"vLLM","subcategory":"Serving","website":"https://vllm.ai/","oss":true,"repositories":[{"url":"https://github.com/vllm-project/vllm","primary":true}]},{"category":"LLMs","homepage_url":"https://www.sglang.io/","id":"llms--serving--sglang","logo":"logos/c801ac352c84d27689070962d2d8bf4d042c369759bac9dfa40d89eac48c027e.png","name":"SGLang","subcategory":"Serving","website":"https://www.sglang.io/","oss":true,"repositories":[{"url":"https://github.com/sgl-project/sglang","primary":true}]}]}
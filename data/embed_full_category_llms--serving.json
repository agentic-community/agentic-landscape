{"github_data":{"https://github.com/sgl-project/sglang":{"contributors":{"count":1104,"url":"https://github.com/sgl-project/sglang/graphs/contributors"},"description":"SGLang is a high-performance serving framework for large language models and multimodal models.","generated_at":"2026-02-18T18:08:20.076298588Z","latest_commit":{"ts":"2026-02-18T16:44:30Z","url":"https://github.com/sgl-project/sglang/commit/150ed881be2cf9a9e64b636226b3c6189d341a7d"},"participation_stats":[57,80,123,134,65,107,66,121,125,119,70,93,85,118,76,111,93,88,78,90,67,92,129,148,191,133,148,124,159,181,136,117,142,186,177,206,186,217,271,200,201,234,293,223,230,239,247,190,203,195,129,203],"stars":23587,"topics":["attention","blackwell","cuda","deepseek","diffusion","glm","gpt-oss","inference","llama","llm","minimax","moe","qwen","qwen-image","reinforcement-learning","transformer","vlm","wan"],"url":"https://github.com/sgl-project/sglang","first_commit":{"ts":"2023-10-09T22:41:15Z","url":"https://github.com/sgl-project/sglang/commit/f6d40df0ee1e1fc53db3edc04bf90575f221cf23"},"languages":{"C":128264,"C++":1370798,"CMake":32098,"Cuda":1660814,"Dockerfile":80798,"Go":105506,"HIP":15490,"Jinja":1205,"Jupyter Notebook":7306,"Makefile":23168,"Python":25627523,"Rust":3035844,"Shell":160137,"Vim Script":914},"latest_release":{"ts":"2026-01-23T22:09:28Z","url":"https://github.com/sgl-project/sglang/releases/tag/v0.5.8"},"license":"Apache License 2.0"},"https://github.com/vllm-project/vllm":{"contributors":{"count":2206,"url":"https://github.com/vllm-project/vllm/graphs/contributors"},"description":"A high-throughput and memory-efficient inference and serving engine for LLMs","generated_at":"2026-02-18T18:08:27.761553031Z","latest_commit":{"ts":"2026-02-18T17:46:53Z","url":"https://github.com/vllm-project/vllm/commit/c0bd8b13da36e62f982929a9f14bc9ef3ff6a56a"},"participation_stats":[131,121,165,161,149,170,143,132,127,197,138,161,137,175,148,128,124,108,120,146,181,152,218,201,208,198,210,186,168,245,294,216,196,221,192,169,168,204,222,275,196,228,211,178,99,124,255,161,208,237,229,190],"stars":70578,"topics":["amd","blackwell","cuda","deepseek","deepseek-v3","gpt","gpt-oss","inference","kimi","llama","llm","llm-serving","model-serving","moe","openai","pytorch","qwen","qwen3","tpu","transformer"],"url":"https://github.com/vllm-project/vllm","first_commit":{"ts":"2023-02-09T11:24:15Z","url":"https://github.com/vllm-project/vllm/commit/e7d9d9c08c79b386f6d0477e87b77a572390317d"},"languages":{"C":95214,"C++":1261514,"CMake":99427,"Cuda":2053194,"Dockerfile":35685,"HCL":1731,"Jinja":6380,"Python":26503324,"Shell":257941},"latest_release":{"ts":"2026-02-04T20:48:08Z","url":"https://github.com/vllm-project/vllm/releases/tag/v0.15.1"},"license":"Apache License 2.0"}},"items":[{"category":"LLMs","homepage_url":"https://vllm.ai/","id":"llms--serving--vllm","logo":"logos/789d223c86d7884c48ea51f8e799e8c0ce952495186131fcaed24c06292d0e45.svg","name":"vLLM","subcategory":"Serving","website":"https://vllm.ai/","oss":true,"repositories":[{"url":"https://github.com/vllm-project/vllm","primary":true}]},{"category":"LLMs","homepage_url":"https://www.sglang.io/","id":"llms--serving--sglang","logo":"logos/c801ac352c84d27689070962d2d8bf4d042c369759bac9dfa40d89eac48c027e.png","name":"SGLang","subcategory":"Serving","website":"https://www.sglang.io/","oss":true,"repositories":[{"url":"https://github.com/sgl-project/sglang","primary":true}]}]}